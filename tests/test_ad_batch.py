# tests/test_ad_batch.py
from typing import List, Tuple

import pytest

from src.config import TASK_CONFIGS
from src.predict import predict_batch

# (ë¬¸ì¥, ê¸°ëŒ€ ë¼ë²¨)
CASES: List[Tuple[str, str]] = [
    # ê´‘ê³ 
    ("ìµœì‹ í° ë¬´ë£Œ ì¦ì • ì´ë²¤íŠ¸!", "ê´‘ê³ "),
    ("ì§€ê¸ˆ í´ë¦­í•˜ë©´ ë¬´ë£Œ ì¦ì •!", "ê´‘ê³ "),
    ("ì§€ê¸ˆ êµ¬ë§¤í•˜ì‹œë©´ ì‚¬ì€í’ˆ ë“œë ¤ìš”", "ê´‘ê³ "),
    ("ë‹¨ 24ì‹œê°„! 1+1 íŠ¹ê°€", "ê´‘ê³ "),
    ("ì„ ì°©ìˆœ 100ëª… ì¿ í° ì§€ê¸‰", "ê´‘ê³ "),
    ("ë§í¬ ì ‘ì† ì‹œ ì¦‰ì‹œ í• ì¸", "ê´‘ê³ "),
    ("ì´ ë§í¬ë¡œ ì‹ ì²­í•˜ì„¸ìš”", "ê´‘ê³ "),
    ("ì²´í—˜ë‹¨ ëª¨ì§‘! ì§€ì› ë§í¬", "ê´‘ê³ "),
    ("ë°°ì†¡ë¹„ ë¬´ë£Œ + ì¶”ê°€ 10% ì¿ í°", "ê´‘ê³ "),
    ("í•œì • ìˆ˜ëŸ‰ ë§ˆì§€ë§‰ ê¸°íšŒ", "ê´‘ê³ "),
    ("êµ¬ë…í•˜ë©´ í¬ì¸íŠ¸ 5ì²œì›", "ê´‘ê³ "),
    ("ìŠ¤í°ì„œ í˜‘ì°¬ ì•ˆë‚´ë“œë¦½ë‹ˆë‹¤", "ê´‘ê³ "),
    ("ì œíœ´ ë¬¸ì˜ëŠ” DM ì£¼ì„¸ìš”", "ê´‘ê³ "),
    ("0ì› ì„¤ì¹˜, ìƒë‹´ ì˜ˆì•½ í´ë¦­", "ê´‘ê³ "),
    ("ê²¨ìš¸ ì„¸ì¼ ìµœëŒ€ 70% OFF", "ê´‘ê³ "),

    # ì •ìƒ
    ("ë°˜ê°€ì›Œìš”", "ì •ìƒ"),
    ("ì˜¤ëŠ˜ ë‚ ì”¨ ì°¸ ì¢‹ë„¤ìš”.", "ì •ìƒ"),
    ("ì•„ì´ì˜ë•Œ ë‹¬ì•„ë†“ëŠ” ìº ì„ í†µí•´ ìš°ì—°íˆ ì‹œì–´ë¨¸ë‹ˆê°€ ë§¨ë°œë¡œ ì¹¨ëŒ€ìœ„ì—ì„œ ë°œë¡œ ì•‰ìœ¼ì‹œê³  ë°œì„ ì«™ í•€ìƒíƒœë¡œ ëˆ„ìœ¼ì‹œëŠ” ì¥ë©´ì„ ë³´ê²Œë¬ê³  ê·¸ê±¸ ë‚¨í¸í•œí…Œ ìì—°ìŠ¤ëŸ½ê²Œ ë§ì„ í–ˆì–´ìš”.. ", "ì •ìƒ"),
    ("ë‚¨í¸ë„ ê·¸ê±´ ì˜ëª»ëœê±°ë¼ í–ˆì§€ë§Œ ì•„ì´ë¥¼ ë´ì£¼ì‹œëŸ¬ ì™€ì£¼ì‹œëŠ” ì‹œì–´ë¨¸ë‹ˆì—ê²Œ ì•Šì¢‹ê²Œ ë§ì”€ë“œë¦¬ê³  ì‹¶ì§€ëŠ” ì•Šì€ë° ì–´ë–¡í•˜ë©´ ì‹¬ê¸°ë¥¼ ë¶ˆí¸í•˜ê²Œ í•´ë“œë¦¬ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ¬ìš´ ë°©ë²•ì´ ì—†ì„ê¹Œìš”? ", "ì •ìƒ"),
    ("ì ì‹¬ ë­ ë“œì…¨ì–´ìš”?", "ì •ìƒ"),
    ("ì´ë²ˆ ì£¼ë§ì— ê°€ì¡± ëª¨ì„ì´ ìˆì–´ìš”.", "ì •ìƒ"),
    ("ë°°ì´ˆë³´ê³  7,8ì•Œ ìˆ™ì œë‚´ì£¼ì…¨ëŠ”ë°â€¦ ëŠ¦ì–´ì§€ëŠ”ê±¸ê¹Œìš”? ì•„ë‹˜ ì§€ë‚˜ê°„ ê±¸ê¹Œìš”.. ì•„ë‹˜ ë°°ë€ì´ ì•ˆëœê±¸ê¹Œìš”â€¦?", "ì •ìƒ"),
    ("ì´ë ‡ê²Œ ë‹¨í˜¸ë°•ì´ì–´ë„ ë˜ë‚˜ìš” ã… ã… ã… ã… ã…‹ã…‹ã…‹ íƒœì–´ë‚˜ì„œ ë³¸ ì¤„ ì¤‘ì— ê°€ì¥ ì„ ëª…í•œ í•œì¤„ì´ë„¤ìš”  ã… ã… ã…  ì´ë ‡ê²Œ ì•ˆì„ ëª…í•´ë„ ëœë‹¨ë‹¤^^ğŸ˜­ ë°°ë€10ì¼ì§¸ì—¬ì„œ í•´ë´¤ëŠ”ë° ã… ã…  ë„ˆë¬´ ë‹¨ë‹¨í•œ ë‹¨í˜¸ë°•ğŸ¤£ ë‚˜ìœë„˜ ã… ã… ã… ã… ã… ğŸ˜‚ ê¸°ëŒ€í•œë§Œí¼ ì‹¤ë§ë„ ì»¤ì§€ë„¤ì˜¹ ", "ì •ìƒ"),
    ("ì–´ë””ë‹¤ ë¬¼ì–´ë³¼ ìˆ˜ë„ ì—†ê³  ì €ëŠ” ë‚¨í¸ì´ë‘ ì‚¬ë‘ ë‚˜ëˆ„ê³  ë‚˜ë©´ ì†Œì¤‘ì´ê°€ ì•„ë‹ˆë¼ ëª©ì´ ì•„í”•ë‹ˆë‹¤", "ì •ìƒ"),
    ("í˜¹ì‹œ ì›í¬ ë‘ì¤„ ì´ˆì´ˆì´ˆì´ˆì´ˆì´ˆì´Ÿì´ˆë§¤ì§ì•„ì´ë¡œ ë³´ì´ì‹œë‚˜ìš”?? ê·¼ë° ë§Œì•½ ë§ë‹¤í•˜ë”ë¼ë„ ì € ìœ„ì¹˜ì— ì¤„ì´ ë‚˜íƒ€ë‚˜ì§„ ì•Šì£ ,,?ã…ã…", "ì •ìƒ"),
    ("ë‹¨í˜¸ë°• í•œì¤„ì´ì£ ,,?", "ì •ìƒ"),
    ("4ë…„ì§¸ ìì„ì‹œë„ì¤‘ì¸ë° ì–¼ë§ˆë‚˜ ì˜ˆìœì²œì‚¬ê°€ ì˜¤ë ¤ê³  ì´ë ‡ê²Œ ëŠ¦ê²Œ ì˜¬ê¹Œìš”ã… ã…  ì´ë²ˆë…„ë„ì—” ê¼­ ì²œì‚¬ë³´ê¸¸ ì›í•˜ë©´ì„œ í‡´ì‚¬í•˜ê³  ë§¤ì¼ ìš´ë™ì¤‘ì´ë„¤ìš© ë‹¤ë“¤ ì €ì²˜ëŸ¼ ì˜¤ë˜ ìì„ì´ ì•ˆë˜ëŠ”ê±¸ê¹Œìš”?ã… ã… ", "ì •ìƒ"),
    ("7ì›” 25ì¼ ~ 31ì¼ ìƒë¦¬ ì–´í”Œìƒ 8ì›” 9ì¼ì´ ë°°ë€ì¼ ì˜ˆìƒì¸ë° ê·¸ëŸ¼ ì´ë²ˆë‹¬ì€ í”¼í¬ì—†ì´ ì§€ë‚˜ê°€ëŠ”ê±´ê°€ìš”.? ã…œã…œ ë°°ë€ì— ë¬¸ì œê°€ ìˆëŠ”ê±°ê² ì£  ? ë°°í…Œê¸° ì´ìš© ì´ˆë³´ë¼ ë„ì›€ ë¶€íƒë“œë ¤ìš”.", "ì •ìƒ"),
    ("ì¿ íŒ¡ìœ¼ë¡œ ì‹œí‚¤ë ¤ëŠ”ë° ì–´ë–¤ê²Œ ì¢‹ì€ê°€ìš”?ã… ã… ", "ì •ìƒ"),
    ("ì—¬ê±´ìƒ ì œê°€ ê±°ì‹¤ì—ì„œ ì—…ë¬´ë¥¼ ë´ì•¼í• ê²½ìš°ëŠ” ì‹œì–´ë¨¸ë‹ˆê°€ ê·¸ ì‹œê°„ì— ë§ì¶° ì•„ì´ë¥¼ ë´ì£¼ëŸ¬ ì˜¤ì‹œëŠ”ë° ë‹¤ë¥¸ë°©ì—ëŠ” ì—ì–´ì»¨ì´ ë”°ë¡œ ì—†ëŠ”ê´€ê³„ë¡œ ì•ˆë°© ë¶€ë¶€ì¹¨ëŒ€ì—ì„œ ì•„ì´ë¥¼ 2ì‹œê°„? ì •ë„ ë´ì¤˜ì•¼ í•˜ëŠ”ê²½ìš°ê°€ ì¼ì£¼ì¼ì— í•œë‘ë²ˆ ì •ë„ ìˆì–´ìš”~ ", "ì •ìƒ"),
    ("ë°°ë€ 10ì¼ì°¨ì¸ë°ã… ã… ã… ã…  ëˆˆì´ë§Œë“  ê°€ì§œì„ ì¸ì§€â€¦ë‘ì¤„ì´ë¼í•´ë„ 10ì¼ì°¨ì— ì´ì •ë„ ì—°í•˜ê¸°ì´ë©´ ì•„ë‹Œê±°ê² ì£ ?? ", "ì •ìƒ"),
]

IDS = [f"{i:02d}_{'ad' if lab == 'ê´‘ê³ ' else 'normal'}" for i, (_, lab) in enumerate(CASES)]


@pytest.mark.parametrize("text,expected", CASES, ids=IDS)
def test_ad_batch_predictions(model_and_tokenizer, max_len, device, text, expected):
    """
    ë°°ì¹˜ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ ë‹¨ê±´ë„ ì˜ˆì¸¡í•´ ë™ì¼ ì½”ë“œ ê²½ë¡œë¥¼ ê²€ì¦.
    """
    model, tokenizer = model_and_tokenizer
    preds = predict_batch(
        model=model,
        tokenizer=tokenizer,
        sentences=[text],
        max_len=max_len,
        device=device,
        label2str=TASK_CONFIGS["ad"]["label2str"],
        log_stats=False,
    )
    assert len(preds) == 1, "ì˜ˆì¸¡ ê²°ê³¼ê°€ 1ê°œê°€ ì•„ë‹™ë‹ˆë‹¤."
    got = preds[0]
    assert got == expected, f"ì…ë ¥: {text}\nì˜ˆì¸¡: {got}\nê¸°ëŒ€: {expected}"


def test_ad_batch_predictions_all(model_and_tokenizer, max_len, device):
    """
    ëª¨ë“  ì¼€ì´ìŠ¤ë¥¼ í•œ ë²ˆì— ë°°ì¹˜ ì˜ˆì¸¡ìœ¼ë¡œ ê²€ì¦í•˜ê³ ,
    í‹€ë¦° í•­ëª©ì´ ìˆìœ¼ë©´ í‘œë¡œ ìƒì„¸ ì¶œë ¥.
    """
    model, tokenizer = model_and_tokenizer
    sentences = [t for t, _ in CASES]
    expected = [e for _, e in CASES]

    preds = predict_batch(
        model=model,
        tokenizer=tokenizer,
        sentences=sentences,
        max_len=max_len,
        device=device,
        label2str=TASK_CONFIGS["ad"]["label2str"],
        log_stats=False,
    )

    mismatches = []
    for i, (inp, exp, got) in enumerate(zip(sentences, expected, preds)):
        if exp != got:
            mismatches.append((i, inp, exp, got))

    if mismatches:
        lines = [
            "\nì˜ˆì¸¡ ë¶ˆì¼ì¹˜ ëª©ë¡:",
            " idx | ì…ë ¥ ë¬¸ì¥                           | ê¸°ëŒ€ | ì˜ˆì¸¡",
            "-----+--------------------------------------+------|------",
        ]
        for idx, inp, exp, got in mismatches:
            lines.append(f"{idx:>4} | {inp[:38]:<38} | {exp:<2} | {got:<2}")
        raise AssertionError("\n".join(lines))

    assert preds == expected
